{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec752a12",
   "metadata": {},
   "source": [
    "Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6fc952",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2461e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from  textblob import TextBlob "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b828d9f3",
   "metadata": {},
   "source": [
    "Handling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f82d0356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35266,)\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('F:/MyGithub/public-sentiment-analysis-based-on-twitter-hashtags/datasets/datasets/dataset.csv',index_col=0)\n",
    "tweets=df['tweetcaption']\n",
    "print(tweets.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee623d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tweets=[tweets[i].split(',') for i in range(len(tweets))]\n",
    "print(new_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfed7dd",
   "metadata": {},
   "source": [
    "Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d8ac2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89459bd0",
   "metadata": {},
   "source": [
    "Building functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd0c9207",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def show(k):\n",
    "    show.counter+=1\n",
    "    print(show.counter,\" ~ \",k)\n",
    "\n",
    "show.counter=0\n",
    "\"\"\"\n",
    "\n",
    "def stemming(tweet):\n",
    "    corpus = []\n",
    "    for i in range(len(tweet)):\n",
    "        review = re.sub('[^a-zA-Z]', ' ', tweet[i]) \n",
    "        #show(review)\n",
    "        review = re.sub(r'[^\\w\\s]', '', review)\n",
    "        #show(review)\n",
    "        review = review.lower()\n",
    "        #show(review)\n",
    "        review = review.split()\n",
    "        #show(review)\n",
    "\n",
    "        review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "        review = ' '.join(review)\n",
    "        corpus.append(review)\n",
    "    return corpus    \n",
    "\n",
    "#x=stemming(tweets[0:][0:100])\n",
    "#print(x)    \n",
    "    #return corpus\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c73d9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos:  0.8380593205920717\n",
      "Neu:  0.009102251460330063\n",
      "Neg:  0.15283842794759825\n"
     ]
    }
   ],
   "source": [
    "def polarity(tweets):\n",
    "    n=0\n",
    "    pos=0\n",
    "    neu=0\n",
    "    neg=0\n",
    "\n",
    "    for tweet in tweets:\n",
    "        n=n+1 \n",
    "        analysis=TextBlob(tweet) \n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            pos=pos+1\n",
    "        elif analysis.sentiment.polarity == 0 :\n",
    "            neu=neu+1\n",
    "        else :\n",
    "            neg=neg+1\n",
    "    \n",
    "    score=[pos/n,neu/n,neg/n]\n",
    "    return score\n",
    "\n",
    "sc=polarity(tweets[0:][0:])\n",
    "print(\"Pos: \",sc[0])\n",
    "print(\"Neu: \",sc[1])\n",
    "print(\"Neg: \",sc[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c15e0e5",
   "metadata": {},
   "source": [
    "Building scores from functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ecff1da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos:  [0.4, 0.5, 0.3, 0.2, 0.4, 0.2, 0.6, 0.3, 0.6, 0.2, 0.4, 0.4, 0.5, 0.7, 0.4, 0.3, 0.8, 0.4, 0.4, 0.2, 0.3, 0.0, 0.5, 0.3, 0.3, 0.4, 0.5, 0.6, 0.3, 0.2, 0.2, 0.4, 0.6, 0.6, 0.3, 0.3, 0.6, 0.2, 0.7, 0.2, 0.4, 0.3, 0.2, 0.5, 0.4, 0.4, 0.5, 0.8, 0.3, 0.4, 0.6, 0.5, 0.6, 0.5, 0.4, 0.2, 0.3, 0.3, 0.2, 0.3, 0.6, 0.4, 0.6, 0.6, 0.0, 0.3, 0.7, 0.4, 0.2, 0.5, 0.2, 0.2, 0.3, 0.4, 0.7, 0.4, 0.5, 0.6, 0.3, 0.5, 0.4, 0.2, 0.3, 0.3, 0.2, 0.1, 0.1, 0.5, 0.6, 0.4, 0.2, 0.3, 0.3, 0.6, 0.6, 0.7, 0.5, 0.4, 0.5, 0.3]\n",
      "neu:  [0.3, 0.5, 0.5, 0.8, 0.4, 0.7, 0.4, 0.5, 0.4, 0.7, 0.5, 0.5, 0.2, 0.3, 0.6, 0.6, 0.2, 0.5, 0.5, 0.5, 0.5, 1.0, 0.4, 0.6, 0.6, 0.3, 0.5, 0.4, 0.5, 0.8, 0.7, 0.4, 0.4, 0.4, 0.5, 0.5, 0.4, 0.7, 0.3, 0.8, 0.5, 0.6, 0.8, 0.2, 0.5, 0.6, 0.4, 0.2, 0.5, 0.6, 0.4, 0.5, 0.4, 0.5, 0.3, 0.8, 0.5, 0.5, 0.7, 0.5, 0.4, 0.4, 0.4, 0.4, 0.2, 0.5, 0.3, 0.5, 0.8, 0.2, 0.7, 0.8, 0.6, 0.5, 0.2, 0.5, 0.5, 0.4, 0.5, 0.5, 0.3, 0.8, 0.5, 0.5, 0.7, 0.7, 0.5, 0.3, 0.4, 0.4, 0.8, 0.6, 0.5, 0.4, 0.4, 0.3, 0.2, 0.5, 0.5, 0.5]\n",
      "neg:  [0.3, 0.0, 0.2, 0.0, 0.2, 0.1, 0.0, 0.2, 0.0, 0.1, 0.1, 0.1, 0.3, 0.0, 0.0, 0.1, 0.0, 0.1, 0.1, 0.3, 0.2, 0.0, 0.1, 0.1, 0.1, 0.3, 0.0, 0.0, 0.2, 0.0, 0.1, 0.2, 0.0, 0.0, 0.2, 0.2, 0.0, 0.1, 0.0, 0.0, 0.1, 0.1, 0.0, 0.3, 0.1, 0.0, 0.1, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.0, 0.2, 0.2, 0.1, 0.2, 0.0, 0.2, 0.0, 0.0, 0.8, 0.2, 0.0, 0.1, 0.0, 0.3, 0.1, 0.0, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.2, 0.0, 0.3, 0.0, 0.2, 0.2, 0.1, 0.2, 0.4, 0.2, 0.0, 0.2, 0.0, 0.1, 0.2, 0.0, 0.0, 0.0, 0.3, 0.1, 0.0, 0.2]\n"
     ]
    }
   ],
   "source": [
    "pos=[]\n",
    "neu=[]\n",
    "neg=[]\n",
    "#print(new_tweets)\n",
    "x=new_tweets[0:][0:1000]\n",
    "\n",
    "for i in x:\n",
    "    p=stemming(i)\n",
    "    score=polarity(p)\n",
    "    pos.append(score[0])\n",
    "    neu.append(score[1])\n",
    "    neg.append(score[2])\n",
    "\n",
    "print(\"pos: \",pos)\n",
    "print(\"neu: \",neu)\n",
    "print(\"neg: \",neg)\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d462d171",
   "metadata": {},
   "source": [
    "Merging scores to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5232dbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pos']=pos\n",
    "df['neu']=neu\n",
    "df['neg']=neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2bea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
