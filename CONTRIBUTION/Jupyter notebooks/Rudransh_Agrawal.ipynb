{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d0d2ad4-a31f-47a0-9c0f-b1383fe52d48",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b434c7ea-8fff-4b48-88fb-d55059ca0af1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9550141-01fc-4c02-a1c1-4d28bf5f8220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\rohit padage\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\rohit padage\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from textblob) (3.6.5)\n",
      "Requirement already satisfied: joblib in c:\\users\\rohit padage\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rohit padage\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>=3.1->textblob) (4.62.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\rohit padage\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>=3.1->textblob) (2021.11.10)\n",
      "Requirement already satisfied: click in c:\\users\\rohit padage\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\rohit padage\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Rohit\n",
      "[nltk_data]     Padage\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Rohit\n",
      "[nltk_data]     Padage\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Rohit\n",
      "[nltk_data]     Padage\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Rohit Padage\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8ce41b-0df3-4c88-b937-3cf3e128a4f8",
   "metadata": {},
   "source": [
    "## Handling the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9681277c-ba6e-42d3-9b4e-941f6625b3bb",
   "metadata": {},
   "source": [
    "In this part I have cleaned the dataset by removing unwanted columns, removing punctuation marks in the tweetcaption column and using only relevant words for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77b7d192-a654-4c43-a6b0-da150c0e7f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>tweetcaption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tuesdayvibes</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>Love it here vacation vibes amazing beautiful ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>realmeC11</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>Best Camera Smartphone under 20k Please vote a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KPSharmaOli</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>shree Why should we have a problem with the pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RheaChakraborty</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>Rhea Chakraborty s Heartbreaking Post On Susha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop_Transfer_Sunita_Yadav</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>We stand for Sunita Yadav Stop the Transfer Wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Data       Date     Time  \\\n",
       "0                 tuesdayvibes  7/14/2020  7:00:21   \n",
       "1                    realmeC11  7/14/2020  7:00:21   \n",
       "2                  KPSharmaOli  7/14/2020  7:00:21   \n",
       "3              RheaChakraborty  7/14/2020  7:00:21   \n",
       "4   Stop_Transfer_Sunita_Yadav  7/14/2020  7:00:21   \n",
       "\n",
       "                                        tweetcaption  \n",
       "0  Love it here vacation vibes amazing beautiful ...  \n",
       "1  Best Camera Smartphone under 20k Please vote a...  \n",
       "2  shree Why should we have a problem with the pe...  \n",
       "3  Rhea Chakraborty s Heartbreaking Post On Susha...  \n",
       "4  We stand for Sunita Yadav Stop the Transfer Wh...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('F:/MyGithub/public-sentiment-analysis-based-on-twitter-hashtags/datasets/datasets/dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37accf34-e5be-4d62-8509-7f50c5907c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>tweetcaption</th>\n",
       "      <th>cleaned_tweetcaption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tuesdayvibes</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>Love it here vacation vibes amazing beautiful ...</td>\n",
       "      <td>Love it here vacation vibes amazing beautiful ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>realmeC11</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>Best Camera Smartphone under 20k Please vote a...</td>\n",
       "      <td>Best Camera Smartphone under k Please vote and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KPSharmaOli</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>shree Why should we have a problem with the pe...</td>\n",
       "      <td>shree Why should we have a problem with the pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RheaChakraborty</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>Rhea Chakraborty s Heartbreaking Post On Susha...</td>\n",
       "      <td>Rhea Chakraborty s Heartbreaking Post On Susha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop_Transfer_Sunita_Yadav</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>We stand for Sunita Yadav Stop the Transfer Wh...</td>\n",
       "      <td>We stand for Sunita Yadav Stop the Transfer Wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Data       Date     Time  \\\n",
       "0                 tuesdayvibes  7/14/2020  7:00:21   \n",
       "1                    realmeC11  7/14/2020  7:00:21   \n",
       "2                  KPSharmaOli  7/14/2020  7:00:21   \n",
       "3              RheaChakraborty  7/14/2020  7:00:21   \n",
       "4   Stop_Transfer_Sunita_Yadav  7/14/2020  7:00:21   \n",
       "\n",
       "                                        tweetcaption  \\\n",
       "0  Love it here vacation vibes amazing beautiful ...   \n",
       "1  Best Camera Smartphone under 20k Please vote a...   \n",
       "2  shree Why should we have a problem with the pe...   \n",
       "3  Rhea Chakraborty s Heartbreaking Post On Susha...   \n",
       "4  We stand for Sunita Yadav Stop the Transfer Wh...   \n",
       "\n",
       "                                cleaned_tweetcaption  \n",
       "0  Love it here vacation vibes amazing beautiful ...  \n",
       "1  Best Camera Smartphone under k Please vote and...  \n",
       "2  shree Why should we have a problem with the pe...  \n",
       "3  Rhea Chakraborty s Heartbreaking Post On Susha...  \n",
       "4  We stand for Sunita Yadav Stop the Transfer Wh...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean(txt):\n",
    "# Removing all special characters and numericals leaving the alphabets\n",
    "    txt = re.sub('[^A-Za-z]+', ' ', txt)\n",
    "    return txt\n",
    "\n",
    "# Cleaning the text in the tweetcaption column\n",
    "data['cleaned_tweetcaption'] = data['tweetcaption'].apply(clean)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f34e18bd-e30a-4945-a000-1ad0caec0e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>tweetcaption</th>\n",
       "      <th>cleaned_tweetcaption</th>\n",
       "      <th>POS_tagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tuesdayvibes</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>Love it here vacation vibes amazing beautiful ...</td>\n",
       "      <td>Love it here vacation vibes amazing beautiful ...</td>\n",
       "      <td>[(Love, v), (vacation, n), (vibes, n), (amazin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>realmeC11</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>Best Camera Smartphone under 20k Please vote a...</td>\n",
       "      <td>Best Camera Smartphone under k Please vote and...</td>\n",
       "      <td>[(Best, n), (Camera, n), (Smartphone, n), (k, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KPSharmaOli</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>shree Why should we have a problem with the pe...</td>\n",
       "      <td>shree Why should we have a problem with the pe...</td>\n",
       "      <td>[(shree, a), (problem, n), (people, n), (probl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RheaChakraborty</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>Rhea Chakraborty s Heartbreaking Post On Susha...</td>\n",
       "      <td>Rhea Chakraborty s Heartbreaking Post On Susha...</td>\n",
       "      <td>[(Rhea, n), (Chakraborty, n), (Heartbreaking, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop_Transfer_Sunita_Yadav</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>We stand for Sunita Yadav Stop the Transfer Wh...</td>\n",
       "      <td>We stand for Sunita Yadav Stop the Transfer Wh...</td>\n",
       "      <td>[(stand, v), (Sunita, n), (Yadav, n), (Stop, n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Data       Date     Time  \\\n",
       "0                 tuesdayvibes  7/14/2020  7:00:21   \n",
       "1                    realmeC11  7/14/2020  7:00:21   \n",
       "2                  KPSharmaOli  7/14/2020  7:00:21   \n",
       "3              RheaChakraborty  7/14/2020  7:00:21   \n",
       "4   Stop_Transfer_Sunita_Yadav  7/14/2020  7:00:21   \n",
       "\n",
       "                                        tweetcaption  \\\n",
       "0  Love it here vacation vibes amazing beautiful ...   \n",
       "1  Best Camera Smartphone under 20k Please vote a...   \n",
       "2  shree Why should we have a problem with the pe...   \n",
       "3  Rhea Chakraborty s Heartbreaking Post On Susha...   \n",
       "4  We stand for Sunita Yadav Stop the Transfer Wh...   \n",
       "\n",
       "                                cleaned_tweetcaption  \\\n",
       "0  Love it here vacation vibes amazing beautiful ...   \n",
       "1  Best Camera Smartphone under k Please vote and...   \n",
       "2  shree Why should we have a problem with the pe...   \n",
       "3  Rhea Chakraborty s Heartbreaking Post On Susha...   \n",
       "4  We stand for Sunita Yadav Stop the Transfer Wh...   \n",
       "\n",
       "                                          POS_tagged  \n",
       "0  [(Love, v), (vacation, n), (vibes, n), (amazin...  \n",
       "1  [(Best, n), (Camera, n), (Smartphone, n), (k, ...  \n",
       "2  [(shree, a), (problem, n), (people, n), (probl...  \n",
       "3  [(Rhea, n), (Chakraborty, n), (Heartbreaking, ...  \n",
       "4  [(stand, v), (Sunita, n), (Yadav, n), (Stop, n...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS tagger dictionary\n",
    "#classifying the parts of senyences as noun, verb, adverb or adjective\n",
    "pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}\n",
    "def token_stop_pos(text):\n",
    "    tags = pos_tag(word_tokenize(text))\n",
    "    newlist = []\n",
    "    for word, tag in tags:\n",
    "        if word.lower() not in set(stopwords.words('english')):\n",
    "            newlist.append(tuple([word, pos_dict.get(tag[0])]))\n",
    "    return newlist\n",
    "\n",
    "data['POS_tagged'] = data['cleaned_tweetcaption'][0:100].apply(token_stop_pos)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56e35433-b4eb-431e-8cd4-c1704d505918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>tweetcaption</th>\n",
       "      <th>cleaned_tweetcaption</th>\n",
       "      <th>POS_tagged</th>\n",
       "      <th>Lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>EkTarfaOutTomorrow</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>9:59:15</td>\n",
       "      <td>Anybody awake EkTarfaOutTomorrow,Mutual feelin...</td>\n",
       "      <td>Anybody awake EkTarfaOutTomorrow Mutual feelin...</td>\n",
       "      <td>[(Anybody, n), (awake, v), (EkTarfaOutTomorrow...</td>\n",
       "      <td>Anybody awake EkTarfaOutTomorrow Mutual feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>NepaliRam</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>9:59:15</td>\n",
       "      <td>The biggest casualty of a NepaliRam would be o...</td>\n",
       "      <td>The biggest casualty of a NepaliRam would be o...</td>\n",
       "      <td>[(biggest, a), (casualty, n), (NepaliRam, n), ...</td>\n",
       "      <td>big casualty NepaliRam would TV channel imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>armyisoverparty</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>9:59:15</td>\n",
       "      <td>nchild Chill Antis try to make armyisoverparty...</td>\n",
       "      <td>nchild Chill Antis try to make armyisoverparty...</td>\n",
       "      <td>[(nchild, a), (Chill, n), (Antis, n), (try, n)...</td>\n",
       "      <td>nchild Chill Antis try make armyisoverparty ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>WorldCup2019</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>9:59:15</td>\n",
       "      <td>Brilliant memories WorldCup2019 WorldCupFinal ...</td>\n",
       "      <td>Brilliant memories WorldCup WorldCupFinal ENGv...</td>\n",
       "      <td>[(Brilliant, a), (memories, n), (WorldCup, n),...</td>\n",
       "      <td>Brilliant memory WorldCup WorldCupFinal ENGv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Tucson</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>9:59:15</td>\n",
       "      <td>Been out and about since 10 am watching the cl...</td>\n",
       "      <td>Been out and about since am watching the cloud...</td>\n",
       "      <td>[(since, None), (watching, v), (clouds, n), (H...</td>\n",
       "      <td>since watch cloud Huge break scatter Come mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Data       Date     Time  \\\n",
       "90   EkTarfaOutTomorrow  7/14/2020  9:59:15   \n",
       "91            NepaliRam  7/14/2020  9:59:15   \n",
       "92      armyisoverparty  7/14/2020  9:59:15   \n",
       "93         WorldCup2019  7/14/2020  9:59:15   \n",
       "94               Tucson  7/14/2020  9:59:15   \n",
       "\n",
       "                                         tweetcaption  \\\n",
       "90  Anybody awake EkTarfaOutTomorrow,Mutual feelin...   \n",
       "91  The biggest casualty of a NepaliRam would be o...   \n",
       "92  nchild Chill Antis try to make armyisoverparty...   \n",
       "93  Brilliant memories WorldCup2019 WorldCupFinal ...   \n",
       "94  Been out and about since 10 am watching the cl...   \n",
       "\n",
       "                                 cleaned_tweetcaption  \\\n",
       "90  Anybody awake EkTarfaOutTomorrow Mutual feelin...   \n",
       "91  The biggest casualty of a NepaliRam would be o...   \n",
       "92  nchild Chill Antis try to make armyisoverparty...   \n",
       "93  Brilliant memories WorldCup WorldCupFinal ENGv...   \n",
       "94  Been out and about since am watching the cloud...   \n",
       "\n",
       "                                           POS_tagged  \\\n",
       "90  [(Anybody, n), (awake, v), (EkTarfaOutTomorrow...   \n",
       "91  [(biggest, a), (casualty, n), (NepaliRam, n), ...   \n",
       "92  [(nchild, a), (Chill, n), (Antis, n), (try, n)...   \n",
       "93  [(Brilliant, a), (memories, n), (WorldCup, n),...   \n",
       "94  [(since, None), (watching, v), (clouds, n), (H...   \n",
       "\n",
       "                                                Lemma  \n",
       "90    Anybody awake EkTarfaOutTomorrow Mutual feel...  \n",
       "91    big casualty NepaliRam would TV channel imag...  \n",
       "92    nchild Chill Antis try make armyisoverparty ...  \n",
       "93    Brilliant memory WorldCup WorldCupFinal ENGv...  \n",
       "94    since watch cloud Huge break scatter Come mo...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using the pos_tagged column data to create a lemma column conatining relevant words\n",
    "my_data=data\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(pos_data):\n",
    "    lemma_rew = \" \"\n",
    "    for word, pos in pos_data:\n",
    "        if not pos:\n",
    "            lemma = word\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "        else:\n",
    "            lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "    return lemma_rew\n",
    "\n",
    "my_data['Lemma'] = my_data['POS_tagged'][0:100].apply(lemmatize)\n",
    "my_data[90:100].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9be3bc-10c7-451f-876d-85b9185bd177",
   "metadata": {},
   "source": [
    "## Building Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256d8aa6-248b-41db-a157-0a59cd9c06da",
   "metadata": {},
   "source": [
    "### Using Rule Based Method- TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c7cf02-1f29-443c-ae0a-81dba27285e5",
   "metadata": {},
   "source": [
    "TextBlob calculates the polarity and subjectivity of a tweet and based on the polarity we judge whether a tweet is in positive, negative or neutral context.\n",
    "Subjective sentences generally refer to personal opinion, emotion or judgment whereas objective refers to factual information.\n",
    "So low subjectivity refers to a facual information whereas a high value refers to a public opinion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c2df75e-468d-4709-8c27-9322fa565ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate subjectivity\n",
    "def getSubjectivity(review):\n",
    "    return TextBlob(review).sentiment.subjectivity\n",
    "# function to calculate polarity\n",
    "def getPolarity(review):\n",
    "    return TextBlob(review).sentiment.polarity\n",
    "\n",
    "# function to analyze the reviews\n",
    "def analysis(score):\n",
    "    if score < 0:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecf1609a-d24b-412e-9026-5ea969f7157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_data = pd.DataFrame(my_data[['tweetcaption', 'Lemma']])\n",
    "#print(blob_data)\n",
    "blob_data=blob_data[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f06bb6ca-ba89-4508-b0c5-bbc59904a797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetcaption</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love it here vacation vibes amazing beautiful ...</td>\n",
       "      <td>Love vacation vibe amaze beautiful cabo mexi...</td>\n",
       "      <td>0.478571</td>\n",
       "      <td>0.142695</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Best Camera Smartphone under 20k Please vote a...</td>\n",
       "      <td>Best Camera Smartphone k Please vote help re...</td>\n",
       "      <td>0.445174</td>\n",
       "      <td>0.200033</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shree Why should we have a problem with the pe...</td>\n",
       "      <td>shree problem people problem Stupid Communis...</td>\n",
       "      <td>0.638750</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rhea Chakraborty s Heartbreaking Post On Susha...</td>\n",
       "      <td>Rhea Chakraborty Heartbreaking Post Sushant ...</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We stand for Sunita Yadav Stop the Transfer Wh...</td>\n",
       "      <td>stand Sunita Yadav Stop Transfer woman empow...</td>\n",
       "      <td>0.515079</td>\n",
       "      <td>0.213228</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        tweetcaption  \\\n",
       "0  Love it here vacation vibes amazing beautiful ...   \n",
       "1  Best Camera Smartphone under 20k Please vote a...   \n",
       "2  shree Why should we have a problem with the pe...   \n",
       "3  Rhea Chakraborty s Heartbreaking Post On Susha...   \n",
       "4  We stand for Sunita Yadav Stop the Transfer Wh...   \n",
       "\n",
       "                                               Lemma  Subjectivity  Polarity  \\\n",
       "0    Love vacation vibe amaze beautiful cabo mexi...      0.478571  0.142695   \n",
       "1    Best Camera Smartphone k Please vote help re...      0.445174  0.200033   \n",
       "2    shree problem people problem Stupid Communis...      0.638750  0.118750   \n",
       "3    Rhea Chakraborty Heartbreaking Post Sushant ...      0.607143  0.142857   \n",
       "4    stand Sunita Yadav Stop Transfer woman empow...      0.515079  0.213228   \n",
       "\n",
       "   Analysis  \n",
       "0  Positive  \n",
       "1  Positive  \n",
       "2  Positive  \n",
       "3  Positive  \n",
       "4  Positive  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_data['Subjectivity'] = blob_data['Lemma'].apply(getSubjectivity) \n",
    "blob_data['Polarity'] = blob_data['Lemma'].apply(getPolarity) \n",
    "blob_data['Analysis'] = blob_data['Polarity'].apply(analysis)\n",
    "blob_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43d21f73-6887-45a4-8cfa-df3a3de9d344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    90\n",
       "Negative    10\n",
       "Name: Analysis, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb_counts = blob_data.Analysis.value_counts()\n",
    "\n",
    "tb_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4779a919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ROHITP~1\\AppData\\Local\\Temp/ipykernel_23076/3706687168.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#print(y2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0my3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m plt.bar(tb_counts,y2 , color ='maroon',\n\u001b[0m\u001b[0;32m      8\u001b[0m         width = 0.4)\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mbar\u001b[1;34m(x, height, width, bottom, align, data, **kwargs)\u001b[0m\n\u001b[0;32m   2385\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'center'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2386\u001b[0m         data=None, **kwargs):\n\u001b[1;32m-> 2387\u001b[1;33m     return gca().bar(\n\u001b[0m\u001b[0;32m   2388\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbottom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malign\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2389\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1410\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1412\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1414\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mbar\u001b[1;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[0;32m   2340\u001b[0m                 \u001b[0myerr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_dx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myerr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_yunits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2342\u001b[1;33m         x, height, width, y, linewidth, hatch = np.broadcast_arrays(\n\u001b[0m\u001b[0;32m   2343\u001b[0m             \u001b[1;31m# Make args iterable too.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2344\u001b[0m             np.atleast_1d(x), height, width, y, linewidth, hatch)\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[1;34m(subok, *args)\u001b[0m\n\u001b[0;32m    536\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_broadcast_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_shape\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;31m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m     \u001b[1;31m# consistently\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m     \u001b[1;31m# unfortunately, it cannot handle 32 or more arguments directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m31\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = {'Pos':tb_counts[0], 'Neg': tb_counts[1] }\n",
    "k=list(data.keys())\n",
    "v=list(data.values())\n",
    "\n",
    "y=blob_data.shape\n",
    "y1=print(y[0])\n",
    "y2=[ i for i in range(0,100,10)]\n",
    "#print(y2) \n",
    "y3=[20,40,60,80]\n",
    "\n",
    "plt.bar(k,v , color ='maroon',\n",
    "        width = 0.4)\n",
    " \n",
    "plt.xlabel(\"Scores\")\n",
    "plt.ylabel(\"No. of tweets\")\n",
    "plt.title(\"Statistics of tweets\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636e2727-4e32-4f73-91ba-170208fccd4a",
   "metadata": {},
   "source": [
    "We can see that we have a higher number of positive tweets in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2393d66-8c5e-4664-8ef0-69380461f10e",
   "metadata": {},
   "source": [
    "### Using Machine Learning Approach- Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3301ffe-8f87-4806-ba04-77a4f5491bb6",
   "metadata": {},
   "source": [
    "In this section I have taken naive bayes model trained on a different dataset of tweets and I have applied it on my dataset. The pretrained model had a accuracy of 73% on that dataset and I have used it to predict the sentiment on our dataset.\n",
    "I have modified the model to fit our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9577f8-d95c-4567-9867-d8612802508c",
   "metadata": {},
   "source": [
    "Please download the [dataset](https://www.kaggle.com/githubsearch/twitter-sentimental-analysis/data) for the below pretrained naive bayes model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf82e5a-b879-4576-9a7b-fcd1909023d5",
   "metadata": {},
   "source": [
    "#### The code for the pretrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bcdac8e-ae8d-4766-b08c-aca422a271c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment          id                          date     query  \\\n",
       "0                0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1                0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2                0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3                0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4                0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...            ...         ...                           ...       ...   \n",
       "1599995          4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996          4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997          4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998          4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999          4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                              tweet  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tweets=pd.read_csv('training.1600000.processed.noemoticon.csv',encoding='latin', \n",
    "                   names = ['sentiment','id','date','query','user','tweet'])\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82cc4753-dddb-4681-821a-24997217933d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (200000, 6)\n"
     ]
    }
   ],
   "source": [
    "tweets = tweets.sample(frac=1)\n",
    "tweets = tweets[:200000]\n",
    "print(\"Dataset shape:\", tweets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "add5edcd-82f7-45fe-a52a-1596b647db70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>377511</th>\n",
       "      <td>0</td>\n",
       "      <td>2051914755</td>\n",
       "      <td>Fri Jun 05 23:08:08 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>miapfirrman</td>\n",
       "      <td>im aching in places I didn't even know I had i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091382</th>\n",
       "      <td>1</td>\n",
       "      <td>1969882703</td>\n",
       "      <td>Sat May 30 01:35:17 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ghbetbeze</td>\n",
       "      <td>@DynamiteSaint Can't disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397554</th>\n",
       "      <td>1</td>\n",
       "      <td>2053982569</td>\n",
       "      <td>Sat Jun 06 06:15:01 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>BexN12</td>\n",
       "      <td>Congrats to my amazing sister for being in lab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647879</th>\n",
       "      <td>0</td>\n",
       "      <td>2236880442</td>\n",
       "      <td>Fri Jun 19 04:44:20 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>T0YAH</td>\n",
       "      <td>@ryan_leslie u only staying in paris though?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319128</th>\n",
       "      <td>0</td>\n",
       "      <td>2002977969</td>\n",
       "      <td>Tue Jun 02 05:36:44 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>FallingUpward</td>\n",
       "      <td>@snflower99  i know what you mean i want my pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372266</th>\n",
       "      <td>1</td>\n",
       "      <td>2051236110</td>\n",
       "      <td>Fri Jun 05 21:16:14 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>dustindikes</td>\n",
       "      <td>Just got done with the grad show. Pretty good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139044</th>\n",
       "      <td>1</td>\n",
       "      <td>1976896393</td>\n",
       "      <td>Sat May 30 19:28:33 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TinaFaith</td>\n",
       "      <td>Finally made it!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506716</th>\n",
       "      <td>1</td>\n",
       "      <td>2174377093</td>\n",
       "      <td>Sun Jun 14 22:25:34 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mojopath</td>\n",
       "      <td>#mojoquiz Hummingbird or TweetAdder? Don't kno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474431</th>\n",
       "      <td>1</td>\n",
       "      <td>2065731972</td>\n",
       "      <td>Sun Jun 07 09:10:54 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>dannybrown</td>\n",
       "      <td>@kwbridge Heathen!!! ;-) I have to admit, I wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536317</th>\n",
       "      <td>0</td>\n",
       "      <td>2198359116</td>\n",
       "      <td>Tue Jun 16 15:58:11 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>airaxDlovesdemi</td>\n",
       "      <td>my computer doesn't drag clips into SV!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment          id                          date     query  \\\n",
       "377511           0  2051914755  Fri Jun 05 23:08:08 PDT 2009  NO_QUERY   \n",
       "1091382          1  1969882703  Sat May 30 01:35:17 PDT 2009  NO_QUERY   \n",
       "1397554          1  2053982569  Sat Jun 06 06:15:01 PDT 2009  NO_QUERY   \n",
       "647879           0  2236880442  Fri Jun 19 04:44:20 PDT 2009  NO_QUERY   \n",
       "319128           0  2002977969  Tue Jun 02 05:36:44 PDT 2009  NO_QUERY   \n",
       "...            ...         ...                           ...       ...   \n",
       "1372266          1  2051236110  Fri Jun 05 21:16:14 PDT 2009  NO_QUERY   \n",
       "1139044          1  1976896393  Sat May 30 19:28:33 PDT 2009  NO_QUERY   \n",
       "1506716          1  2174377093  Sun Jun 14 22:25:34 PDT 2009  NO_QUERY   \n",
       "1474431          1  2065731972  Sun Jun 07 09:10:54 PDT 2009  NO_QUERY   \n",
       "536317           0  2198359116  Tue Jun 16 15:58:11 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                              tweet  \n",
       "377511       miapfirrman  im aching in places I didn't even know I had i...  \n",
       "1091382        ghbetbeze                     @DynamiteSaint Can't disagree   \n",
       "1397554           BexN12  Congrats to my amazing sister for being in lab...  \n",
       "647879             T0YAH      @ryan_leslie u only staying in paris though?   \n",
       "319128     FallingUpward  @snflower99  i know what you mean i want my pr...  \n",
       "...                  ...                                                ...  \n",
       "1372266      dustindikes  Just got done with the grad show. Pretty good ...  \n",
       "1139044        TinaFaith                                  Finally made it!   \n",
       "1506716         mojopath  #mojoquiz Hummingbird or TweetAdder? Don't kno...  \n",
       "1474431       dannybrown  @kwbridge Heathen!!! ;-) I have to admit, I wa...  \n",
       "536317   airaxDlovesdemi            my computer doesn't drag clips into SV!  \n",
       "\n",
       "[200000 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['sentiment']=tweets['sentiment'].replace(4,1)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0a84168-7d02-405e-8c0d-bc415bff301c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>377511</th>\n",
       "      <td>0</td>\n",
       "      <td>im aching in places I didn't even know I had i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091382</th>\n",
       "      <td>1</td>\n",
       "      <td>@DynamiteSaint Can't disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397554</th>\n",
       "      <td>1</td>\n",
       "      <td>Congrats to my amazing sister for being in lab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647879</th>\n",
       "      <td>0</td>\n",
       "      <td>@ryan_leslie u only staying in paris though?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319128</th>\n",
       "      <td>0</td>\n",
       "      <td>@snflower99  i know what you mean i want my pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596172</th>\n",
       "      <td>1</td>\n",
       "      <td>@JeriWB You wanted to know how one cooks beans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944638</th>\n",
       "      <td>1</td>\n",
       "      <td>@dahliamartin Haha Dahls! *hugs* I hope you're...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590192</th>\n",
       "      <td>0</td>\n",
       "      <td>@robocarrot I so get that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744054</th>\n",
       "      <td>0</td>\n",
       "      <td>Twitter was acting dumb so I had to get a new ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965677</th>\n",
       "      <td>1</td>\n",
       "      <td>Ahhh she's making daddy proud! She'll be cente...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                              tweet\n",
       "377511           0  im aching in places I didn't even know I had i...\n",
       "1091382          1                     @DynamiteSaint Can't disagree \n",
       "1397554          1  Congrats to my amazing sister for being in lab...\n",
       "647879           0      @ryan_leslie u only staying in paris though? \n",
       "319128           0  @snflower99  i know what you mean i want my pr...\n",
       "1596172          1  @JeriWB You wanted to know how one cooks beans...\n",
       "944638           1  @dahliamartin Haha Dahls! *hugs* I hope you're...\n",
       "590192           0                         @robocarrot I so get that \n",
       "744054           0  Twitter was acting dumb so I had to get a new ...\n",
       "965677           1  Ahhh she's making daddy proud! She'll be cente..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.drop(['date','query','user'], axis=1, inplace=True)\n",
    "tweets.drop('id', axis=1, inplace=True)\n",
    "tweets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf6e4a27-5c3c-4bfa-822b-31ec0b82aa8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0.0\n",
       "tweet        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tweets.isnull().sum() / len(tweets))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "079c322f-3511-4295-8fe7-281b5f2a8557",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['tweet'] = tweets['tweet'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "209b5060-64a4-4a46-b15b-79b32a652045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of the data is:         200000\n",
      "No. of positve tagged sentences is:  99924\n",
      "No. of negative tagged sentences is: 100076\n"
     ]
    }
   ],
   "source": [
    "positives = tweets['sentiment'][tweets.sentiment == 1 ]\n",
    "negatives = tweets['sentiment'][tweets.sentiment == 0 ]\n",
    "\n",
    "print('Total length of the data is:         {}'.format(tweets.shape[0]))\n",
    "print('No. of positve tagged sentences is:  {}'.format(len(positives)))\n",
    "print('No. of negative tagged sentences is: {}'.format(len(negatives)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75185c51-a0a7-430d-8c70-cc54d94ce718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'out', 'who', \"that'll\", 'once', 'by', 'those', 'above', 'yourselves', 'what', 'hadn', 'theirs', 'they', \"doesn't\", 'with', 'to', 'below', 'shouldn', 'both', 'before', 'you', 'down', 'ain', 'myself', 'mustn', \"don't\", \"weren't\", 'same', 'in', 'ours', 'such', 'your', 'it', 'were', \"isn't\", 'very', 'she', 'all', 'of', 'just', 'being', 'so', 'aren', 'no', 'doesn', 'wouldn', 'his', 'these', 'between', 'this', 'o', 'hasn', 'as', 'won', \"haven't\", 'own', 'only', 'here', 'until', \"mightn't\", 'during', \"wasn't\", 'now', 'him', 'them', \"aren't\", 'few', 'too', \"mustn't\", 'has', 'when', \"you'd\", 'didn', 'not', 'how', 'their', 'about', 'more', 'after', 'ourselves', 'i', 'mightn', 'my', 'hers', 'did', \"didn't\", 'ma', 'wasn', 'doing', 'he', 'that', 'weren', 'if', 'further', 'then', 'than', 'couldn', 'against', 'or', \"couldn't\", \"she's\", 'an', 'at', 'there', 'have', \"you're\", 'where', \"needn't\", 'don', \"wouldn't\", 's', 'up', 'yourself', 'isn', \"hasn't\", 'why', 'yours', 'whom', 'itself', 'most', 'themselves', 'other', 'having', 'each', \"hadn't\", 'been', 'herself', 'on', 'needn', 'haven', 'am', \"you've\", 'had', 'but', \"shouldn't\", 'we', 'some', 'd', 'and', 'any', 'nor', 'its', 'be', 'her', 'off', 'again', 'the', 'was', 'himself', 'does', 'is', 'into', 'which', 'do', 'are', 'can', 're', 'from', 'will', 'me', 't', \"you'll\", \"shan't\", \"it's\", 'y', \"won't\", 'shan', 'll', 'our', 've', \"should've\", 'because', 'over', 'm', 'a', 'through', 'for', 'under', 'should', 'while'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/rudra/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# nltk\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "#Stop Words: A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) \n",
    "#that a search engine has been programmed to ignore,\n",
    "#both when indexing entries for searching and when retrieving them as the result of a search query.\n",
    "nltk.download('stopwords')\n",
    "stopword = set(stopwords.words('english'))\n",
    "print(stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02a6fea5-d4b5-4846-a083-487b8815025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "urlPattern = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
    "userPattern = '@[^\\s]+'\n",
    "some = 'amp,today,tomorrow,going,girl'\n",
    "def process_tweets(tweet):\n",
    "  # Lower Casing\n",
    "    tweet = re.sub(r\"he's\", \"he is\", tweet)\n",
    "    tweet = re.sub(r\"there's\", \"there is\", tweet)\n",
    "    tweet = re.sub(r\"We're\", \"We are\", tweet)\n",
    "    tweet = re.sub(r\"That's\", \"That is\", tweet)\n",
    "    tweet = re.sub(r\"won't\", \"will not\", tweet)\n",
    "    tweet = re.sub(r\"they're\", \"they are\", tweet)\n",
    "    tweet = re.sub(r\"Can't\", \"Cannot\", tweet)\n",
    "    tweet = re.sub(r\"wasn't\", \"was not\", tweet)\n",
    "    tweet = re.sub(r\"don\\x89Ûªt\", \"do not\", tweet)\n",
    "    tweet = re.sub(r\"aren't\", \"are not\", tweet)\n",
    "    tweet = re.sub(r\"isn't\", \"is not\", tweet)\n",
    "    tweet = re.sub(r\"What's\", \"What is\", tweet)\n",
    "    tweet = re.sub(r\"haven't\", \"have not\", tweet)\n",
    "    tweet = re.sub(r\"hasn't\", \"has not\", tweet)\n",
    "    tweet = re.sub(r\"There's\", \"There is\", tweet)\n",
    "    tweet = re.sub(r\"He's\", \"He is\", tweet)\n",
    "    tweet = re.sub(r\"It's\", \"It is\", tweet)\n",
    "    tweet = re.sub(r\"You're\", \"You are\", tweet)\n",
    "    tweet = re.sub(r\"I'M\", \"I am\", tweet)\n",
    "    tweet = re.sub(r\"shouldn't\", \"should not\", tweet)\n",
    "    tweet = re.sub(r\"wouldn't\", \"would not\", tweet)\n",
    "    tweet = re.sub(r\"i'm\", \"I am\", tweet)\n",
    "    tweet = re.sub(r\"I\\x89Ûªm\", \"I am\", tweet)\n",
    "    tweet = re.sub(r\"I'm\", \"I am\", tweet)\n",
    "    tweet = re.sub(r\"Isn't\", \"is not\", tweet)\n",
    "    tweet = re.sub(r\"Here's\", \"Here is\", tweet)\n",
    "    tweet = re.sub(r\"you've\", \"you have\", tweet)\n",
    "    tweet = re.sub(r\"you\\x89Ûªve\", \"you have\", tweet)\n",
    "    tweet = re.sub(r\"we're\", \"we are\", tweet)\n",
    "    tweet = re.sub(r\"what's\", \"what is\", tweet)\n",
    "    tweet = re.sub(r\"couldn't\", \"could not\", tweet)\n",
    "    tweet = re.sub(r\"we've\", \"we have\", tweet)\n",
    "    tweet = re.sub(r\"it\\x89Ûªs\", \"it is\", tweet)\n",
    "    tweet = re.sub(r\"doesn\\x89Ûªt\", \"does not\", tweet)\n",
    "    tweet = re.sub(r\"It\\x89Ûªs\", \"It is\", tweet)\n",
    "    tweet = re.sub(r\"Here\\x89Ûªs\", \"Here is\", tweet)\n",
    "    tweet = re.sub(r\"who's\", \"who is\", tweet)\n",
    "    tweet = re.sub(r\"I\\x89Ûªve\", \"I have\", tweet)\n",
    "    tweet = re.sub(r\"y'all\", \"you all\", tweet)\n",
    "    tweet = re.sub(r\"can\\x89Ûªt\", \"cannot\", tweet)\n",
    "    tweet = re.sub(r\"would've\", \"would have\", tweet)\n",
    "    tweet = re.sub(r\"it'll\", \"it will\", tweet)\n",
    "    tweet = re.sub(r\"we'll\", \"we will\", tweet)\n",
    "    tweet = re.sub(r\"wouldn\\x89Ûªt\", \"would not\", tweet)\n",
    "    tweet = re.sub(r\"We've\", \"We have\", tweet)\n",
    "    tweet = re.sub(r\"he'll\", \"he will\", tweet)\n",
    "    tweet = re.sub(r\"Y'all\", \"You all\", tweet)\n",
    "    tweet = re.sub(r\"Weren't\", \"Were not\", tweet)\n",
    "    tweet = re.sub(r\"Didn't\", \"Did not\", tweet)\n",
    "    tweet = re.sub(r\"they'll\", \"they will\", tweet)\n",
    "    tweet = re.sub(r\"they'd\", \"they would\", tweet)\n",
    "    tweet = re.sub(r\"DON'T\", \"DO NOT\", tweet)\n",
    "    tweet = re.sub(r\"That\\x89Ûªs\", \"That is\", tweet)\n",
    "    tweet = re.sub(r\"they've\", \"they have\", tweet)\n",
    "    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n",
    "    tweet = re.sub(r\"should've\", \"should have\", tweet)\n",
    "    tweet = re.sub(r\"You\\x89Ûªre\", \"You are\", tweet)\n",
    "    tweet = re.sub(r\"where's\", \"where is\", tweet)\n",
    "    tweet = re.sub(r\"Don\\x89Ûªt\", \"Do not\", tweet)\n",
    "    tweet = re.sub(r\"we'd\", \"we would\", tweet)\n",
    "    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n",
    "    tweet = re.sub(r\"weren't\", \"were not\", tweet)\n",
    "    tweet = re.sub(r\"They're\", \"They are\", tweet)\n",
    "    tweet = re.sub(r\"Can\\x89Ûªt\", \"Cannot\", tweet)\n",
    "    tweet = re.sub(r\"you\\x89Ûªll\", \"you will\", tweet)\n",
    "    tweet = re.sub(r\"I\\x89Ûªd\", \"I would\", tweet)\n",
    "    tweet = re.sub(r\"let's\", \"let us\", tweet)\n",
    "    tweet = re.sub(r\"it's\", \"it is\", tweet)\n",
    "    tweet = re.sub(r\"can't\", \"cannot\", tweet)\n",
    "    tweet = re.sub(r\"don't\", \"do not\", tweet)\n",
    "    tweet = re.sub(r\"you're\", \"you are\", tweet)\n",
    "    tweet = re.sub(r\"i've\", \"I have\", tweet)\n",
    "    tweet = re.sub(r\"that's\", \"that is\", tweet)\n",
    "    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n",
    "    tweet = re.sub(r\"doesn't\", \"does not\", tweet)\n",
    "    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n",
    "    tweet = re.sub(r\"didn't\", \"did not\", tweet)\n",
    "    tweet = re.sub(r\"ain't\", \"am not\", tweet)\n",
    "    tweet = re.sub(r\"you'll\", \"you will\", tweet)\n",
    "    tweet = re.sub(r\"I've\", \"I have\", tweet)\n",
    "    tweet = re.sub(r\"Don't\", \"do not\", tweet)\n",
    "    tweet = re.sub(r\"I'll\", \"I will\", tweet)\n",
    "    tweet = re.sub(r\"I'd\", \"I would\", tweet)\n",
    "    tweet = re.sub(r\"Let's\", \"Let us\", tweet)\n",
    "    tweet = re.sub(r\"you'd\", \"You would\", tweet)\n",
    "    tweet = re.sub(r\"It's\", \"It is\", tweet)\n",
    "    tweet = re.sub(r\"Ain't\", \"am not\", tweet)\n",
    "    tweet = re.sub(r\"Haven't\", \"Have not\", tweet)\n",
    "    tweet = re.sub(r\"Could've\", \"Could have\", tweet)\n",
    "    tweet = re.sub(r\"youve\", \"you have\", tweet)  \n",
    "    tweet = re.sub(r\"donå«t\", \"do not\", tweet)  \n",
    "    \n",
    "    tweet = re.sub(r\"some1\", \"someone\", tweet)\n",
    "    tweet = re.sub(r\"yrs\", \"years\", tweet)\n",
    "    tweet = re.sub(r\"hrs\", \"hours\", tweet)\n",
    "    tweet = re.sub(r\"2morow|2moro\", \"tomorrow\", tweet)\n",
    "    tweet = re.sub(r\"2day\", \"today\", tweet)\n",
    "    tweet = re.sub(r\"4got|4gotten\", \"forget\", tweet)\n",
    "    tweet = re.sub(r\"b-day|bday\", \"b-day\", tweet)\n",
    "    tweet = re.sub(r\"mother's\", \"mother\", tweet)\n",
    "    tweet = re.sub(r\"mom's\", \"mom\", tweet)\n",
    "    tweet = re.sub(r\"dad's\", \"dad\", tweet)\n",
    "    tweet = re.sub(r\"hahah|hahaha|hahahaha\", \"haha\", tweet)\n",
    "    tweet = re.sub(r\"lmao|lolz|rofl\", \"lol\", tweet)\n",
    "    tweet = re.sub(r\"thanx|thnx\", \"thanks\", tweet)\n",
    "    tweet = re.sub(r\"goood\", \"good\", tweet)\n",
    "    tweet = re.sub(r\"some1\", \"someone\", tweet)\n",
    "    tweet = re.sub(r\"some1\", \"someone\", tweet)\n",
    "    tweet = tweet.lower()\n",
    "    tweet=tweet[1:]\n",
    "    # Removing all URls \n",
    "    tweet = re.sub(urlPattern,'',tweet)\n",
    "    # Removing all @username.\n",
    "    tweet = re.sub(userPattern,'', tweet) \n",
    "    #remove some words\n",
    "    tweet= re.sub(some,'',tweet)\n",
    "    #Remove punctuations\n",
    "    tweet = tweet.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "    #tokenizing words\n",
    "    tokens = word_tokenize(tweet)\n",
    "    #tokens = [w for w in tokens if len(w)>2]\n",
    "    #Removing Stop Words\n",
    "    final_tokens = [w for w in tokens if w not in stopword]\n",
    "    #reducing a word to its word stem \n",
    "    wordLemm = WordNetLemmatizer()\n",
    "    finalwords=[]\n",
    "    for w in final_tokens:\n",
    "      if len(w)>1:\n",
    "        word = wordLemm.lemmatize(w)\n",
    "        finalwords.append(word)\n",
    "    return ' '.join(finalwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ced537e-d885-444a-96b7-f7cc7d13f579",
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviations = {\n",
    "    \"$\" : \" dollar \",\n",
    "    \"€\" : \" euro \",\n",
    "    \"4ao\" : \"for adults only\",\n",
    "    \"a.m\" : \"before midday\",\n",
    "    \"a3\" : \"anytime anywhere anyplace\",\n",
    "    \"aamof\" : \"as a matter of fact\",\n",
    "    \"acct\" : \"account\",\n",
    "    \"adih\" : \"another day in hell\",\n",
    "    \"afaic\" : \"as far as i am concerned\",\n",
    "    \"afaict\" : \"as far as i can tell\",\n",
    "    \"afaik\" : \"as far as i know\",\n",
    "    \"afair\" : \"as far as i remember\",\n",
    "    \"afk\" : \"away from keyboard\",\n",
    "    \"app\" : \"application\",\n",
    "    \"approx\" : \"approximately\",\n",
    "    \"apps\" : \"applications\",\n",
    "    \"asap\" : \"as soon as possible\",\n",
    "    \"asl\" : \"age, sex, location\",\n",
    "    \"atk\" : \"at the keyboard\",\n",
    "    \"ave.\" : \"avenue\",\n",
    "    \"aymm\" : \"are you my mother\",\n",
    "    \"ayor\" : \"at your own risk\", \n",
    "    \"b&b\" : \"bed and breakfast\",\n",
    "    \"b+b\" : \"bed and breakfast\",\n",
    "    \"b.c\" : \"before christ\",\n",
    "    \"b2b\" : \"business to business\",\n",
    "    \"b2c\" : \"business to customer\",\n",
    "    \"b4\" : \"before\",\n",
    "    \"b4n\" : \"bye for now\",\n",
    "    \"b@u\" : \"back at you\",\n",
    "    \"bae\" : \"before anyone else\",\n",
    "    \"bak\" : \"back at keyboard\",\n",
    "    \"bbbg\" : \"bye bye be good\",\n",
    "    \"bbc\" : \"british broadcasting corporation\",\n",
    "    \"bbias\" : \"be back in a second\",\n",
    "    \"bbl\" : \"be back later\",\n",
    "    \"bbs\" : \"be back soon\",\n",
    "    \"be4\" : \"before\",\n",
    "    \"bfn\" : \"bye for now\",\n",
    "    \"blvd\" : \"boulevard\",\n",
    "    \"bout\" : \"about\",\n",
    "    \"brb\" : \"be right back\",\n",
    "    \"bros\" : \"brothers\",\n",
    "    \"brt\" : \"be right there\",\n",
    "    \"bsaaw\" : \"big smile and a wink\",\n",
    "    \"btw\" : \"by the way\",\n",
    "    \"bwl\" : \"bursting with laughter\",\n",
    "    \"c/o\" : \"care of\",\n",
    "    \"cet\" : \"central european time\",\n",
    "    \"cf\" : \"compare\",\n",
    "    \"cia\" : \"central intelligence agency\",\n",
    "    \"csl\" : \"can not stop laughing\",\n",
    "    \"cu\" : \"see you\",\n",
    "    \"cul8r\" : \"see you later\",\n",
    "    \"cv\" : \"curriculum vitae\",\n",
    "    \"cwot\" : \"complete waste of time\",\n",
    "    \"cya\" : \"see you\",\n",
    "    \"cyt\" : \"see you tomorrow\",\n",
    "    \"dae\" : \"does anyone else\",\n",
    "    \"dbmib\" : \"do not bother me i am busy\",\n",
    "    \"diy\" : \"do it yourself\",\n",
    "    \"dm\" : \"direct message\",\n",
    "    \"dwh\" : \"during work hours\",\n",
    "    \"e123\" : \"easy as one two three\",\n",
    "    \"eet\" : \"eastern european time\",\n",
    "    \"eg\" : \"example\",\n",
    "    \"embm\" : \"early morning business meeting\",\n",
    "    \"encl\" : \"enclosed\",\n",
    "    \"encl.\" : \"enclosed\",\n",
    "    \"etc\" : \"and so on\",\n",
    "    \"faq\" : \"frequently asked questions\",\n",
    "    \"fawc\" : \"for anyone who cares\",\n",
    "    \"fb\" : \"facebook\",\n",
    "    \"fc\" : \"fingers crossed\",\n",
    "    \"fig\" : \"figure\",\n",
    "    \"fimh\" : \"forever in my heart\", \n",
    "    \"ft.\" : \"feet\",\n",
    "    \"ft\" : \"featuring\",\n",
    "    \"ftl\" : \"for the loss\",\n",
    "    \"ftw\" : \"for the win\",\n",
    "    \"fwiw\" : \"for what it is worth\",\n",
    "    \"fyi\" : \"for your information\",\n",
    "    \"g9\" : \"genius\",\n",
    "    \"gahoy\" : \"get a hold of yourself\",\n",
    "    \"gal\" : \"get a life\",\n",
    "    \"gcse\" : \"general certificate of secondary education\",\n",
    "    \"gfn\" : \"gone for now\",\n",
    "    \"gg\" : \"good game\",\n",
    "    \"gl\" : \"good luck\",\n",
    "    \"glhf\" : \"good luck have fun\",\n",
    "    \"gmt\" : \"greenwich mean time\",\n",
    "    \"gmta\" : \"great minds think alike\",\n",
    "    \"gn\" : \"good night\",\n",
    "    \"g.o.a.t\" : \"greatest of all time\",\n",
    "    \"goat\" : \"greatest of all time\",\n",
    "    \"goi\" : \"get over it\",\n",
    "    \"gps\" : \"global positioning system\",\n",
    "    \"gr8\" : \"great\",\n",
    "    \"gratz\" : \"congratulations\",\n",
    "    \"gyal\" : \"girl\",\n",
    "    \"h&c\" : \"hot and cold\",\n",
    "    \"hp\" : \"horsepower\",\n",
    "    \"hr\" : \"hour\",\n",
    "    \"hrh\" : \"his royal highness\",\n",
    "    \"ht\" : \"height\",\n",
    "    \"ibrb\" : \"i will be right back\",\n",
    "    \"ic\" : \"i see\",\n",
    "    \"icq\" : \"i seek you\",\n",
    "    \"icymi\" : \"in case you missed it\",\n",
    "    \"idc\" : \"i do not care\",\n",
    "    \"idgadf\" : \"i do not give a damn fuck\",\n",
    "    \"idgaf\" : \"i do not give a fuck\",\n",
    "    \"idk\" : \"i do not know\",\n",
    "    \"ie\" : \"that is\",\n",
    "    \"i.e\" : \"that is\",\n",
    "    \"ifyp\" : \"i feel your pain\",\n",
    "    \"IG\" : \"instagram\",\n",
    "    \"iirc\" : \"if i remember correctly\",\n",
    "    \"ilu\" : \"i love you\",\n",
    "    \"ily\" : \"i love you\",\n",
    "    \"imho\" : \"in my humble opinion\",\n",
    "    \"imo\" : \"in my opinion\",\n",
    "    \"imu\" : \"i miss you\",\n",
    "    \"iow\" : \"in other words\",\n",
    "    \"irl\" : \"in real life\",\n",
    "    \"j4f\" : \"just for fun\",\n",
    "    \"jic\" : \"just in case\",\n",
    "    \"jk\" : \"just kidding\",\n",
    "    \"jsyk\" : \"just so you know\",\n",
    "    \"l8r\" : \"later\",\n",
    "    \"lb\" : \"pound\",\n",
    "    \"lbs\" : \"pounds\",\n",
    "    \"ldr\" : \"long distance relationship\",\n",
    "    \"lmao\" : \"laugh my ass off\",\n",
    "    \"lmfao\" : \"laugh my fucking ass off\",\n",
    "    \"lol\" : \"laughing out loud\",\n",
    "    \"ltd\" : \"limited\",\n",
    "    \"ltns\" : \"long time no see\",\n",
    "    \"m8\" : \"mate\",\n",
    "    \"mf\" : \"motherfucker\",\n",
    "    \"mfs\" : \"motherfuckers\",\n",
    "    \"mfw\" : \"my face when\",\n",
    "    \"mofo\" : \"motherfucker\",\n",
    "    \"mph\" : \"miles per hour\",\n",
    "    \"mr\" : \"mister\",\n",
    "    \"mrw\" : \"my reaction when\",\n",
    "    \"ms\" : \"miss\",\n",
    "    \"mte\" : \"my thoughts exactly\",\n",
    "    \"nagi\" : \"not a good idea\",\n",
    "    \"nbc\" : \"national broadcasting company\",\n",
    "    \"nbd\" : \"not big deal\",\n",
    "    \"nfs\" : \"not for sale\",\n",
    "    \"ngl\" : \"not going to lie\",\n",
    "    \"nhs\" : \"national health service\",\n",
    "    \"nrn\" : \"no reply necessary\",\n",
    "    \"nsfl\" : \"not safe for life\",\n",
    "    \"nsfw\" : \"not safe for work\",\n",
    "    \"nth\" : \"nice to have\",\n",
    "    \"nvr\" : \"never\",\n",
    "    \"nyc\" : \"new york city\",\n",
    "    \"oc\" : \"original content\",\n",
    "    \"og\" : \"original\",\n",
    "    \"ohp\" : \"overhead projector\",\n",
    "    \"oic\" : \"oh i see\",\n",
    "    \"omdb\" : \"over my dead body\",\n",
    "    \"omg\" : \"oh my god\",\n",
    "    \"omw\" : \"on my way\",\n",
    "    \"p.a\" : \"per annum\",\n",
    "    \"p.m\" : \"after midday\",\n",
    "    \"pm\" : \"prime minister\",\n",
    "    \"poc\" : \"people of color\",\n",
    "    \"pov\" : \"point of view\",\n",
    "    \"pp\" : \"pages\",\n",
    "    \"ppl\" : \"people\",\n",
    "    \"prw\" : \"parents are watching\",\n",
    "    \"ps\" : \"postscript\",\n",
    "    \"pt\" : \"point\",\n",
    "    \"ptb\" : \"please text back\",\n",
    "    \"pto\" : \"please turn over\",\n",
    "    \"qpsa\" : \"what happens\", \n",
    "    \"ratchet\" : \"rude\",\n",
    "    \"rbtl\" : \"read between the lines\",\n",
    "    \"rlrt\" : \"real life retweet\", \n",
    "    \"rofl\" : \"rolling on the floor laughing\",\n",
    "    \"roflol\" : \"rolling on the floor laughing out loud\",\n",
    "    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
    "    \"rt\" : \"retweet\",\n",
    "    \"ruok\" : \"are you ok\",\n",
    "    \"sfw\" : \"safe for work\",\n",
    "     \"sk8\" : \"skate\",\n",
    "    \"smh\" : \"shake my head\",\n",
    "    \"sq\" : \"square\",\n",
    "    \"srsly\" : \"seriously\", \n",
    "    \"ssdd\" : \"same stuff different day\",\n",
    "    \"tbh\" : \"to be honest\",\n",
    "    \"tbs\" : \"tablespooful\",\n",
    "    \"tbsp\" : \"tablespooful\",\n",
    "    \"tfw\" : \"that feeling when\",\n",
    "    \"thks\" : \"thank you\",\n",
    "    \"tho\" : \"though\",\n",
    "    \"thx\" : \"thank you\",\n",
    "    \"tia\" : \"thanks in advance\",\n",
    "    \"til\" : \"today i learned\",\n",
    "    \"tl;dr\" : \"too long i did not read\",\n",
    "    \"tldr\" : \"too long i did not read\",\n",
    "    \"tmb\" : \"tweet me back\",\n",
    "    \"tntl\" : \"trying not to laugh\",\n",
    "    \"ttyl\" : \"talk to you later\",\n",
    "    \"u\" : \"you\",\n",
    "    \"u2\" : \"you too\",\n",
    "    \"u4e\" : \"yours for ever\",\n",
    "    \"utc\" : \"coordinated universal time\",\n",
    "    \"w/\" : \"with\",\n",
    "    \"w/o\" : \"without\",\n",
    "    \"w8\" : \"wait\",\n",
    "    \"wassup\" : \"what is up\",\n",
    "    \"wb\" : \"welcome back\",\n",
    "    \"wtf\" : \"what the fuck\",\n",
    "    \"wtg\" : \"way to go\",\n",
    "    \"wtpa\" : \"where the party at\",\n",
    "    \"wuf\" : \"where are you from\",\n",
    "    \"wuzup\" : \"what is up\",\n",
    "    \"wywh\" : \"wish you were here\",\n",
    "    \"yd\" : \"yard\",\n",
    "    \"ygtr\" : \"you got that right\",\n",
    "    \"ynk\" : \"you never know\",\n",
    "    \"zzz\" : \"sleeping bored and tired\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9a70b46-1bcb-4426-b337-e8059160563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_abbrev_in_text(tweet):\n",
    "    t=[]\n",
    "    words=tweet.split()\n",
    "    t = [abbreviations[w.lower()] if w.lower() in abbreviations.keys() else w for w in words]\n",
    "    return ' '.join(t)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14418d6a-8033-4249-9181-462deefa8ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "      <th>processed_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>377511</th>\n",
       "      <td>0</td>\n",
       "      <td>im aching in places I didn't even know I had i...</td>\n",
       "      <td>aching place even know inside lt3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091382</th>\n",
       "      <td>1</td>\n",
       "      <td>@DynamiteSaint Can't disagree</td>\n",
       "      <td>dynamitesaint disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397554</th>\n",
       "      <td>1</td>\n",
       "      <td>Congrats to my amazing sister for being in lab...</td>\n",
       "      <td>ongrats amazing sister labor day welcome ronni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647879</th>\n",
       "      <td>0</td>\n",
       "      <td>@ryan_leslie u only staying in paris though?</td>\n",
       "      <td>ryanleslie staying paris though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319128</th>\n",
       "      <td>0</td>\n",
       "      <td>@snflower99  i know what you mean i want my pr...</td>\n",
       "      <td>snflower99 know mean want pre baby body before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372266</th>\n",
       "      <td>1</td>\n",
       "      <td>Just got done with the grad show. Pretty good ...</td>\n",
       "      <td>ust got done grad show pretty good outcome fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139044</th>\n",
       "      <td>1</td>\n",
       "      <td>Finally made it!</td>\n",
       "      <td>inally made</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506716</th>\n",
       "      <td>1</td>\n",
       "      <td>#mojoquiz Hummingbird or TweetAdder? Don't kno...</td>\n",
       "      <td>mojoquiz hummingbird tweetadder know care gt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474431</th>\n",
       "      <td>1</td>\n",
       "      <td>@kwbridge Heathen!!! ;-) I have to admit, I wa...</td>\n",
       "      <td>kwbridge heathen admit pleasantly surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536317</th>\n",
       "      <td>0</td>\n",
       "      <td>my computer doesn't drag clips into SV!</td>\n",
       "      <td>computer drag clip sv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                              tweet  \\\n",
       "377511           0  im aching in places I didn't even know I had i...   \n",
       "1091382          1                     @DynamiteSaint Can't disagree    \n",
       "1397554          1  Congrats to my amazing sister for being in lab...   \n",
       "647879           0      @ryan_leslie u only staying in paris though?    \n",
       "319128           0  @snflower99  i know what you mean i want my pr...   \n",
       "...            ...                                                ...   \n",
       "1372266          1  Just got done with the grad show. Pretty good ...   \n",
       "1139044          1                                  Finally made it!    \n",
       "1506716          1  #mojoquiz Hummingbird or TweetAdder? Don't kno...   \n",
       "1474431          1  @kwbridge Heathen!!! ;-) I have to admit, I wa...   \n",
       "536317           0            my computer doesn't drag clips into SV!   \n",
       "\n",
       "                                          processed_tweets  \n",
       "377511                   aching place even know inside lt3  \n",
       "1091382                             dynamitesaint disagree  \n",
       "1397554  ongrats amazing sister labor day welcome ronni...  \n",
       "647879                     ryanleslie staying paris though  \n",
       "319128   snflower99 know mean want pre baby body before...  \n",
       "...                                                    ...  \n",
       "1372266  ust got done grad show pretty good outcome fac...  \n",
       "1139044                                        inally made  \n",
       "1506716       mojoquiz hummingbird tweetadder know care gt  \n",
       "1474431        kwbridge heathen admit pleasantly surprised  \n",
       "536317                               computer drag clip sv  \n",
       "\n",
       "[200000 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['processed_tweets'] = tweets['tweet'].apply(lambda x: process_tweets(x))\n",
    "tweets['processed_tweets'] = tweets['processed_tweets'].apply(lambda x: convert_abbrev_in_text(x))\n",
    "print('Text Preprocessing complete.')\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c8383a0-b23f-4893-a059-630be359acf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "      <th>processed_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>377511</th>\n",
       "      <td>0</td>\n",
       "      <td>im aching in places I didn't even know I had i...</td>\n",
       "      <td>aching place even know inside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091382</th>\n",
       "      <td>1</td>\n",
       "      <td>@DynamiteSaint Can't disagree</td>\n",
       "      <td>dynamitesaint disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397554</th>\n",
       "      <td>1</td>\n",
       "      <td>Congrats to my amazing sister for being in lab...</td>\n",
       "      <td>ongrats amazing sister labor welcome ronnie oa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647879</th>\n",
       "      <td>0</td>\n",
       "      <td>@ryan_leslie u only staying in paris though?</td>\n",
       "      <td>ryanleslie staying paris though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319128</th>\n",
       "      <td>0</td>\n",
       "      <td>@snflower99  i know what you mean i want my pr...</td>\n",
       "      <td>snflower99 know mean want baby body before bab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                              tweet  \\\n",
       "377511           0  im aching in places I didn't even know I had i...   \n",
       "1091382          1                     @DynamiteSaint Can't disagree    \n",
       "1397554          1  Congrats to my amazing sister for being in lab...   \n",
       "647879           0      @ryan_leslie u only staying in paris though?    \n",
       "319128           0  @snflower99  i know what you mean i want my pr...   \n",
       "\n",
       "                                          processed_tweets  \n",
       "377511                       aching place even know inside  \n",
       "1091382                             dynamitesaint disagree  \n",
       "1397554  ongrats amazing sister labor welcome ronnie oa...  \n",
       "647879                     ryanleslie staying paris though  \n",
       "319128   snflower99 know mean want baby body before bab...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing shortwords\n",
    "tweets['processed_tweets']=tweets['processed_tweets'].apply(lambda x: \" \".join([w for w in x.split() if len(w)>3]))\n",
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c66492eb-e032-49d6-82e3-1de74d83fbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /home/rudra/.local/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/rudra/.local/lib/python3.8/site-packages (from sklearn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/rudra/.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/rudra/.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sklearn) (1.21.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/rudra/.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn\n",
    "from sklearn.utils import shuffle\n",
    "tweets =  shuffle(tweets).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd6f9776-dba9-4001-b57f-cabdd3ef372c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                         [love, help]\n",
       "1    [mikasounds, killing, video, seen, absolutly, ...\n",
       "2     [awful, tired, looking, forward, college, today]\n",
       "3                                      [tilly15, yeah]\n",
       "4                            [mileyfanfeed, following]\n",
       "Name: processed_tweets, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenization\n",
    "tokenized_tweet=tweets['processed_tweets'].apply(lambda x: x.split())\n",
    "tokenized_tweet.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7fa72fbb-ecaf-4e6b-97d4-20ce3cc9e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize,max_features = 93435) ## Changed the number of max features to make it compatible\n",
    "text_counts = cv.fit_transform(tweets['processed_tweets'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62e0e611-50b5-4176-9e68-0aa97df7e201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=text_counts\n",
    "y=tweets['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=19)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "235705f3-2706-4e57-9106-d7f451a66f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score =  [0.729525 0.728975 0.73745  0.73475  0.72825 ]\n",
      "Train accuracy =82.22%\n",
      "Test accuracy =73.01%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from math import *\n",
    "cnb = ComplementNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "cross_cnb = cross_val_score(cnb, X, y,n_jobs = -1)\n",
    "print(\"Cross Validation score = \",cross_cnb)                \n",
    "print (\"Train accuracy ={:.2f}%\".format(cnb.score(X_train,y_train)*100))\n",
    "print (\"Test accuracy ={:.2f}%\".format(cnb.score(X_test,y_test)*100))\n",
    "train_acc_cnb=cnb.score(X_train,y_train)\n",
    "test_acc_cnb=cnb.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174efda8-beaf-4bb9-b4b5-daf10843fda2",
   "metadata": {},
   "source": [
    "The above code was related to the training of the naive bayes model on a different dataset and I have changed the number of max_features to make it compatible with our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50628868-6d26-4d64-a4dd-385366b613ed",
   "metadata": {},
   "source": [
    "#### Prediction of the sentiments on our Dataset using the  modified pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a0b5fa8-2195-4ad7-9b8e-55b0cfe6c18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token1 = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv1 = CountVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = token1.tokenize)\n",
    "text_counts1 = cv1.fit_transform(my_data['Lemma'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "414ae53d-146a-45bb-b082-6036ce7aaec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cnb.predict(text_counts1) ##predicting the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8eb003fd-8182-4914-ad8d-1c2f46ddd7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "84edb316-432a-4b65-925f-98d046379239",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_data['NB_results'] = ''\n",
    "for a in range(len(y_pred)):\n",
    "    if y_pred[a] :\n",
    "        blob_data['NB_results'][a] = 'Positive'\n",
    "    else:\n",
    "        blob_data['NB_results'][a] = 'Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2b38a2bb-5082-4a37-8c07-77e5ec5b1608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetcaption</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Analysis</th>\n",
       "      <th>NB_results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love it here vacation vibes amazing beautiful ...</td>\n",
       "      <td>Love vacation vibe amaze beautiful cabo mexi...</td>\n",
       "      <td>0.478571</td>\n",
       "      <td>0.142695</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Best Camera Smartphone under 20k Please vote a...</td>\n",
       "      <td>Best Camera Smartphone k Please vote help re...</td>\n",
       "      <td>0.445174</td>\n",
       "      <td>0.200033</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shree Why should we have a problem with the pe...</td>\n",
       "      <td>shree problem people problem Stupid Communis...</td>\n",
       "      <td>0.638750</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rhea Chakraborty s Heartbreaking Post On Susha...</td>\n",
       "      <td>Rhea Chakraborty Heartbreaking Post Sushant ...</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We stand for Sunita Yadav Stop the Transfer Wh...</td>\n",
       "      <td>stand Sunita Yadav Stop Transfer woman empow...</td>\n",
       "      <td>0.515079</td>\n",
       "      <td>0.213228</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        tweetcaption  \\\n",
       "0  Love it here vacation vibes amazing beautiful ...   \n",
       "1  Best Camera Smartphone under 20k Please vote a...   \n",
       "2  shree Why should we have a problem with the pe...   \n",
       "3  Rhea Chakraborty s Heartbreaking Post On Susha...   \n",
       "4  We stand for Sunita Yadav Stop the Transfer Wh...   \n",
       "\n",
       "                                               Lemma  Subjectivity  Polarity  \\\n",
       "0    Love vacation vibe amaze beautiful cabo mexi...      0.478571  0.142695   \n",
       "1    Best Camera Smartphone k Please vote help re...      0.445174  0.200033   \n",
       "2    shree problem people problem Stupid Communis...      0.638750  0.118750   \n",
       "3    Rhea Chakraborty Heartbreaking Post Sushant ...      0.607143  0.142857   \n",
       "4    stand Sunita Yadav Stop Transfer woman empow...      0.515079  0.213228   \n",
       "\n",
       "   Analysis NB_results  \n",
       "0  Positive   Negative  \n",
       "1  Positive   Negative  \n",
       "2  Positive   Positive  \n",
       "3  Positive   Negative  \n",
       "4  Positive   Negative  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ca9310d4-84ed-4c16-9ba8-0b5c8802c21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    24597\n",
       "Negative    10669\n",
       "Name: NB_results, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_data.NB_results.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ccf97372-ac1a-44b6-919e-101ed4945d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    29591\n",
       "Negative     5675\n",
       "Name: Analysis, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_data.Analysis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b07725db-8d81-4a2b-98cc-ce3149feaa9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>tweetcaption</th>\n",
       "      <th>cleaned_tweetcaption</th>\n",
       "      <th>POS_tagged</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>(Blob_Subjectivity, Blob_polarity, Blob Analysis, NB Analysis)</th>\n",
       "      <th>Blob_Subjectivity</th>\n",
       "      <th>Blob_Polarity</th>\n",
       "      <th>Blob Analysis</th>\n",
       "      <th>NB Analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tuesdayvibes</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>Love it here vacation vibes amazing beautiful ...</td>\n",
       "      <td>Love it here vacation vibes amazing beautiful ...</td>\n",
       "      <td>[(Love, v), (vacation, n), (vibes, n), (amazin...</td>\n",
       "      <td>Love vacation vibe amaze beautiful cabo mexi...</td>\n",
       "      <td></td>\n",
       "      <td>0.478571</td>\n",
       "      <td>0.142695</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>realmeC11</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>Best Camera Smartphone under 20k Please vote a...</td>\n",
       "      <td>Best Camera Smartphone under k Please vote and...</td>\n",
       "      <td>[(Best, n), (Camera, n), (Smartphone, n), (k, ...</td>\n",
       "      <td>Best Camera Smartphone k Please vote help re...</td>\n",
       "      <td></td>\n",
       "      <td>0.445174</td>\n",
       "      <td>0.200033</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KPSharmaOli</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>shree Why should we have a problem with the pe...</td>\n",
       "      <td>shree Why should we have a problem with the pe...</td>\n",
       "      <td>[(shree, a), (problem, n), (people, n), (probl...</td>\n",
       "      <td>shree problem people problem Stupid Communis...</td>\n",
       "      <td></td>\n",
       "      <td>0.638750</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RheaChakraborty</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>Rhea Chakraborty s Heartbreaking Post On Susha...</td>\n",
       "      <td>Rhea Chakraborty s Heartbreaking Post On Susha...</td>\n",
       "      <td>[(Rhea, n), (Chakraborty, n), (Heartbreaking, ...</td>\n",
       "      <td>Rhea Chakraborty Heartbreaking Post Sushant ...</td>\n",
       "      <td></td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop_Transfer_Sunita_Yadav</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>We stand for Sunita Yadav Stop the Transfer Wh...</td>\n",
       "      <td>We stand for Sunita Yadav Stop the Transfer Wh...</td>\n",
       "      <td>[(stand, v), (Sunita, n), (Yadav, n), (Stop, n...</td>\n",
       "      <td>stand Sunita Yadav Stop Transfer woman empow...</td>\n",
       "      <td></td>\n",
       "      <td>0.515079</td>\n",
       "      <td>0.213228</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Data       Date     Time  \\\n",
       "0                 tuesdayvibes  7/14/2020  7:00:21   \n",
       "1                    realmeC11  7/14/2020  7:00:21   \n",
       "2                  KPSharmaOli  7/14/2020  7:00:21   \n",
       "3              RheaChakraborty  7/14/2020  7:00:21   \n",
       "4   Stop_Transfer_Sunita_Yadav  7/14/2020  7:00:21   \n",
       "\n",
       "                                        tweetcaption  \\\n",
       "0  Love it here vacation vibes amazing beautiful ...   \n",
       "1  Best Camera Smartphone under 20k Please vote a...   \n",
       "2  shree Why should we have a problem with the pe...   \n",
       "3  Rhea Chakraborty s Heartbreaking Post On Susha...   \n",
       "4  We stand for Sunita Yadav Stop the Transfer Wh...   \n",
       "\n",
       "                                cleaned_tweetcaption  \\\n",
       "0  Love it here vacation vibes amazing beautiful ...   \n",
       "1  Best Camera Smartphone under k Please vote and...   \n",
       "2  shree Why should we have a problem with the pe...   \n",
       "3  Rhea Chakraborty s Heartbreaking Post On Susha...   \n",
       "4  We stand for Sunita Yadav Stop the Transfer Wh...   \n",
       "\n",
       "                                          POS_tagged  \\\n",
       "0  [(Love, v), (vacation, n), (vibes, n), (amazin...   \n",
       "1  [(Best, n), (Camera, n), (Smartphone, n), (k, ...   \n",
       "2  [(shree, a), (problem, n), (people, n), (probl...   \n",
       "3  [(Rhea, n), (Chakraborty, n), (Heartbreaking, ...   \n",
       "4  [(stand, v), (Sunita, n), (Yadav, n), (Stop, n...   \n",
       "\n",
       "                                               Lemma  \\\n",
       "0    Love vacation vibe amaze beautiful cabo mexi...   \n",
       "1    Best Camera Smartphone k Please vote help re...   \n",
       "2    shree problem people problem Stupid Communis...   \n",
       "3    Rhea Chakraborty Heartbreaking Post Sushant ...   \n",
       "4    stand Sunita Yadav Stop Transfer woman empow...   \n",
       "\n",
       "  (Blob_Subjectivity, Blob_polarity, Blob Analysis, NB Analysis)  \\\n",
       "0                                                                  \n",
       "1                                                                  \n",
       "2                                                                  \n",
       "3                                                                  \n",
       "4                                                                  \n",
       "\n",
       "   Blob_Subjectivity  Blob_Polarity Blob Analysis NB Analysis  \n",
       "0           0.478571       0.142695      Positive    Negative  \n",
       "1           0.445174       0.200033      Positive    Negative  \n",
       "2           0.638750       0.118750      Positive    Positive  \n",
       "3           0.607143       0.142857      Positive    Negative  \n",
       "4           0.515079       0.213228      Positive    Negative  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "22cfefd1-d6c3-4682-997e-0fcb2c09b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data['Blob_Subjectivity']=blob_data['Subjectivity']\n",
    "my_data['Blob_Polarity']=blob_data['Polarity']\n",
    "my_data['Blob Analysis']=blob_data['Analysis']\n",
    "my_data['NB Analysis']=blob_data['NB_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a15931c4-34b7-4904-982a-35b672b0109b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>tweetcaption</th>\n",
       "      <th>cleaned_tweetcaption</th>\n",
       "      <th>POS_tagged</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>(Blob_Subjectivity, Blob_polarity, Blob Analysis, NB Analysis)</th>\n",
       "      <th>Blob_Subjectivity</th>\n",
       "      <th>Blob_Polarity</th>\n",
       "      <th>Blob Analysis</th>\n",
       "      <th>NB Analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tuesdayvibes</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>Love it here vacation vibes amazing beautiful ...</td>\n",
       "      <td>Love it here vacation vibes amazing beautiful ...</td>\n",
       "      <td>[(Love, v), (vacation, n), (vibes, n), (amazin...</td>\n",
       "      <td>Love vacation vibe amaze beautiful cabo mexi...</td>\n",
       "      <td></td>\n",
       "      <td>0.478571</td>\n",
       "      <td>0.142695</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>realmeC11</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>Best Camera Smartphone under 20k Please vote a...</td>\n",
       "      <td>Best Camera Smartphone under k Please vote and...</td>\n",
       "      <td>[(Best, n), (Camera, n), (Smartphone, n), (k, ...</td>\n",
       "      <td>Best Camera Smartphone k Please vote help re...</td>\n",
       "      <td></td>\n",
       "      <td>0.445174</td>\n",
       "      <td>0.200033</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KPSharmaOli</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>shree Why should we have a problem with the pe...</td>\n",
       "      <td>shree Why should we have a problem with the pe...</td>\n",
       "      <td>[(shree, a), (problem, n), (people, n), (probl...</td>\n",
       "      <td>shree problem people problem Stupid Communis...</td>\n",
       "      <td></td>\n",
       "      <td>0.638750</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RheaChakraborty</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>Rhea Chakraborty s Heartbreaking Post On Susha...</td>\n",
       "      <td>Rhea Chakraborty s Heartbreaking Post On Susha...</td>\n",
       "      <td>[(Rhea, n), (Chakraborty, n), (Heartbreaking, ...</td>\n",
       "      <td>Rhea Chakraborty Heartbreaking Post Sushant ...</td>\n",
       "      <td></td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop_Transfer_Sunita_Yadav</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>We stand for Sunita Yadav Stop the Transfer Wh...</td>\n",
       "      <td>We stand for Sunita Yadav Stop the Transfer Wh...</td>\n",
       "      <td>[(stand, v), (Sunita, n), (Yadav, n), (Stop, n...</td>\n",
       "      <td>stand Sunita Yadav Stop Transfer woman empow...</td>\n",
       "      <td></td>\n",
       "      <td>0.515079</td>\n",
       "      <td>0.213228</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Data       Date     Time  \\\n",
       "0                 tuesdayvibes  7/14/2020  7:00:21   \n",
       "1                    realmeC11  7/14/2020  7:00:21   \n",
       "2                  KPSharmaOli  7/14/2020  7:00:21   \n",
       "3              RheaChakraborty  7/14/2020  7:00:21   \n",
       "4   Stop_Transfer_Sunita_Yadav  7/14/2020  7:00:21   \n",
       "\n",
       "                                        tweetcaption  \\\n",
       "0  Love it here vacation vibes amazing beautiful ...   \n",
       "1  Best Camera Smartphone under 20k Please vote a...   \n",
       "2  shree Why should we have a problem with the pe...   \n",
       "3  Rhea Chakraborty s Heartbreaking Post On Susha...   \n",
       "4  We stand for Sunita Yadav Stop the Transfer Wh...   \n",
       "\n",
       "                                cleaned_tweetcaption  \\\n",
       "0  Love it here vacation vibes amazing beautiful ...   \n",
       "1  Best Camera Smartphone under k Please vote and...   \n",
       "2  shree Why should we have a problem with the pe...   \n",
       "3  Rhea Chakraborty s Heartbreaking Post On Susha...   \n",
       "4  We stand for Sunita Yadav Stop the Transfer Wh...   \n",
       "\n",
       "                                          POS_tagged  \\\n",
       "0  [(Love, v), (vacation, n), (vibes, n), (amazin...   \n",
       "1  [(Best, n), (Camera, n), (Smartphone, n), (k, ...   \n",
       "2  [(shree, a), (problem, n), (people, n), (probl...   \n",
       "3  [(Rhea, n), (Chakraborty, n), (Heartbreaking, ...   \n",
       "4  [(stand, v), (Sunita, n), (Yadav, n), (Stop, n...   \n",
       "\n",
       "                                               Lemma  \\\n",
       "0    Love vacation vibe amaze beautiful cabo mexi...   \n",
       "1    Best Camera Smartphone k Please vote help re...   \n",
       "2    shree problem people problem Stupid Communis...   \n",
       "3    Rhea Chakraborty Heartbreaking Post Sushant ...   \n",
       "4    stand Sunita Yadav Stop Transfer woman empow...   \n",
       "\n",
       "  (Blob_Subjectivity, Blob_polarity, Blob Analysis, NB Analysis)  \\\n",
       "0                                                                  \n",
       "1                                                                  \n",
       "2                                                                  \n",
       "3                                                                  \n",
       "4                                                                  \n",
       "\n",
       "   Blob_Subjectivity  Blob_Polarity Blob Analysis NB Analysis  \n",
       "0           0.478571       0.142695      Positive    Negative  \n",
       "1           0.445174       0.200033      Positive    Negative  \n",
       "2           0.638750       0.118750      Positive    Positive  \n",
       "3           0.607143       0.142857      Positive    Negative  \n",
       "4           0.515079       0.213228      Positive    Negative  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "568b23f7-61cc-4754-8d90-bebf13d34c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>tweetcaption</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>Blob_Subjectivity</th>\n",
       "      <th>Blob_Polarity</th>\n",
       "      <th>Blob Analysis</th>\n",
       "      <th>NB Analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tuesdayvibes</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>Love it here vacation vibes amazing beautiful ...</td>\n",
       "      <td>Love vacation vibe amaze beautiful cabo mexi...</td>\n",
       "      <td>0.478571</td>\n",
       "      <td>0.142695</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>realmeC11</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>Best Camera Smartphone under 20k Please vote a...</td>\n",
       "      <td>Best Camera Smartphone k Please vote help re...</td>\n",
       "      <td>0.445174</td>\n",
       "      <td>0.200033</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KPSharmaOli</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>shree Why should we have a problem with the pe...</td>\n",
       "      <td>shree problem people problem Stupid Communis...</td>\n",
       "      <td>0.638750</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RheaChakraborty</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>Rhea Chakraborty s Heartbreaking Post On Susha...</td>\n",
       "      <td>Rhea Chakraborty Heartbreaking Post Sushant ...</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop_Transfer_Sunita_Yadav</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>We stand for Sunita Yadav Stop the Transfer Wh...</td>\n",
       "      <td>stand Sunita Yadav Stop Transfer woman empow...</td>\n",
       "      <td>0.515079</td>\n",
       "      <td>0.213228</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Data       Date     Time  \\\n",
       "0                 tuesdayvibes  7/14/2020  7:00:21   \n",
       "1                    realmeC11  7/14/2020  7:00:21   \n",
       "2                  KPSharmaOli  7/14/2020  7:00:21   \n",
       "3              RheaChakraborty  7/14/2020  7:00:21   \n",
       "4   Stop_Transfer_Sunita_Yadav  7/14/2020  7:00:21   \n",
       "\n",
       "                                        tweetcaption  \\\n",
       "0  Love it here vacation vibes amazing beautiful ...   \n",
       "1  Best Camera Smartphone under 20k Please vote a...   \n",
       "2  shree Why should we have a problem with the pe...   \n",
       "3  Rhea Chakraborty s Heartbreaking Post On Susha...   \n",
       "4  We stand for Sunita Yadav Stop the Transfer Wh...   \n",
       "\n",
       "                                               Lemma  Blob_Subjectivity  \\\n",
       "0    Love vacation vibe amaze beautiful cabo mexi...           0.478571   \n",
       "1    Best Camera Smartphone k Please vote help re...           0.445174   \n",
       "2    shree problem people problem Stupid Communis...           0.638750   \n",
       "3    Rhea Chakraborty Heartbreaking Post Sushant ...           0.607143   \n",
       "4    stand Sunita Yadav Stop Transfer woman empow...           0.515079   \n",
       "\n",
       "   Blob_Polarity Blob Analysis NB Analysis  \n",
       "0       0.142695      Positive    Negative  \n",
       "1       0.200033      Positive    Negative  \n",
       "2       0.118750      Positive    Positive  \n",
       "3       0.142857      Positive    Negative  \n",
       "4       0.213228      Positive    Negative  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data = my_data.drop(['cleaned_tweetcaption','POS_tagged',('Blob_Subjectivity', 'Blob_polarity', 'Blob Analysis', 'NB Analysis')],axis=1)\n",
    "fin_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3eeb8d38-2364-443c-8117-d0d62703c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data.rename(columns ={'Lemma':'Cleaned tweetcaption'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5fdf298b-c21b-4084-8e76-611e82ab11da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>tweetcaption</th>\n",
       "      <th>Cleaned tweetcaption</th>\n",
       "      <th>Blob_Subjectivity</th>\n",
       "      <th>Blob_Polarity</th>\n",
       "      <th>Blob Analysis</th>\n",
       "      <th>NB Analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tuesdayvibes</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>Love it here vacation vibes amazing beautiful ...</td>\n",
       "      <td>Love vacation vibe amaze beautiful cabo mexi...</td>\n",
       "      <td>0.478571</td>\n",
       "      <td>0.142695</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>realmeC11</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>Best Camera Smartphone under 20k Please vote a...</td>\n",
       "      <td>Best Camera Smartphone k Please vote help re...</td>\n",
       "      <td>0.445174</td>\n",
       "      <td>0.200033</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KPSharmaOli</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>shree Why should we have a problem with the pe...</td>\n",
       "      <td>shree problem people problem Stupid Communis...</td>\n",
       "      <td>0.638750</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RheaChakraborty</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>Rhea Chakraborty s Heartbreaking Post On Susha...</td>\n",
       "      <td>Rhea Chakraborty Heartbreaking Post Sushant ...</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop_Transfer_Sunita_Yadav</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>We stand for Sunita Yadav Stop the Transfer Wh...</td>\n",
       "      <td>stand Sunita Yadav Stop Transfer woman empow...</td>\n",
       "      <td>0.515079</td>\n",
       "      <td>0.213228</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Data       Date     Time  \\\n",
       "0                 tuesdayvibes  7/14/2020  7:00:21   \n",
       "1                    realmeC11  7/14/2020  7:00:21   \n",
       "2                  KPSharmaOli  7/14/2020  7:00:21   \n",
       "3              RheaChakraborty  7/14/2020  7:00:21   \n",
       "4   Stop_Transfer_Sunita_Yadav  7/14/2020  7:00:21   \n",
       "\n",
       "                                        tweetcaption  \\\n",
       "0  Love it here vacation vibes amazing beautiful ...   \n",
       "1  Best Camera Smartphone under 20k Please vote a...   \n",
       "2  shree Why should we have a problem with the pe...   \n",
       "3  Rhea Chakraborty s Heartbreaking Post On Susha...   \n",
       "4  We stand for Sunita Yadav Stop the Transfer Wh...   \n",
       "\n",
       "                                Cleaned tweetcaption  Blob_Subjectivity  \\\n",
       "0    Love vacation vibe amaze beautiful cabo mexi...           0.478571   \n",
       "1    Best Camera Smartphone k Please vote help re...           0.445174   \n",
       "2    shree problem people problem Stupid Communis...           0.638750   \n",
       "3    Rhea Chakraborty Heartbreaking Post Sushant ...           0.607143   \n",
       "4    stand Sunita Yadav Stop Transfer woman empow...           0.515079   \n",
       "\n",
       "   Blob_Polarity Blob Analysis NB Analysis  \n",
       "0       0.142695      Positive    Negative  \n",
       "1       0.200033      Positive    Negative  \n",
       "2       0.118750      Positive    Positive  \n",
       "3       0.142857      Positive    Negative  \n",
       "4       0.213228      Positive    Negative  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "09cdc344-7d3b-41cc-bef7-9a3b95afb773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive    24597\n",
      "Negative    10669\n",
      "Name: NB Analysis, dtype: int64\n",
      "Positive    29591\n",
      "Negative     5675\n",
      "Name: Blob Analysis, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(fin_data['NB Analysis'].value_counts())\n",
    "print(fin_data['Blob Analysis'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef312b4-4525-40e6-a77a-1f8f762fe362",
   "metadata": {},
   "source": [
    "##### We can observe finally that in TextBlob application the number of positive tweets is more than the number of negative tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bde01dc-f71d-4b04-a925-f5acebcabb5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
